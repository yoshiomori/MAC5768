{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "O EP3 tem dois objetivos principais: \n",
    "\n",
    "Parte 3.1- Segmentação do objeto de interesse: O objetivo desta etapa é segmentar o  objeto do fundo, produzindo uma imagem binária: 0 para o fundo e 1 para o objeto. Dois tipos de segmentação serão usados: manual, para geração do ground-truth, e automática usando algum algoritmo de sua escolha. \n",
    "\n",
    "Parte 3.2- Classificação do objeto de interesse. Ou seja, aplicar PCA e SVM para classificar os objetos entre as classes definidas.\n",
    "\n",
    "Nas duas etapas, a acurácia das soluções serão calculadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Header 3.2\n",
    "\n",
    "3.2- Classificação do objeto de interesse. Esses dois objetivos devem ser organizados em 2 seções diferentes ou dois JN diferentes. \n",
    "\n",
    "Uso de PCA e SVM para classificar os objetos coletados.\n",
    "\n",
    "--------------------\n",
    "Autores: Luan Carlos da Silva Casagrande\n",
    "Paulo Henrique da Silveira\n",
    "Yoshio Mori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bibliotécas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "from skimage import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from skimage.transform import resize\n",
    "import os \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that recursively goes through directories levels and returns all folder names in a specific directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllPerLevel(in_path, in_cLevel, in_fLevel):\n",
    "    dirs = os.listdir(in_path)\n",
    "    if(in_cLevel<in_fLevel):\n",
    "        data = []\n",
    "        for item in dirs:\n",
    "            data.extend(getAllPerLevel(os.path.join(in_path,item), in_cLevel+1, in_fLevel))\n",
    "        data = [item.lower() for item in data]\n",
    "        dirs = np.unique(data)\n",
    "        return dirs\n",
    "    else:\n",
    "        dirs = np.unique(dirs)\n",
    "        return [item.lower() for item in dirs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leitura e organização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "inPath = 'autoSegmentationFeret'\n",
    "\n",
    "sizeRef = 256\n",
    "\n",
    "dirFormat = os.path.join(inPath, '{obj_class}\\\\{lighting}\\\\{place}\\\\{background}')\n",
    "\n",
    "classes = getAllPerLevel(inPath, 0, 0)\n",
    "lightingTypes = getAllPerLevel(inPath, 0, 1)\n",
    "places = getAllPerLevel(inPath, 0, 2)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for objClassID in range(len(classes)):\n",
    "    objClass = classes[objClassID]\n",
    "    dictComb = {}\n",
    "    for lighting in lightingTypes:\n",
    "        for place in places:\n",
    "            backgrounds = getAllPerLevel(os.path.join(inPath, objClass, lighting, place), 0, 0)\n",
    "            dictBackgrounds = {}\n",
    "            for background in backgrounds:\n",
    "                aux = {'obj_class': objClass,\n",
    "                       'lighting': lighting,\n",
    "                       'place': place,\n",
    "                       'background': background}\n",
    "                pathAux = dirFormat.format(**aux)                \n",
    "                dirs = os.listdir(pathAux)\n",
    "                for dirFile in dirs:\n",
    "                    img = io.imread(os.path.join(pathAux, dirFile))\n",
    "                    img = resize(img, (sizeRef, sizeRef),\n",
    "                       anti_aliasing=True)\n",
    "                    X.append(img.flatten())\n",
    "                    y.append(objClassID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extração das features. \n",
    "\n",
    "PCA das features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_compoenents = 500\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "pca = PCA(n_components=n_components, svd_solver='randomized',\n",
    "          whiten=True).fit(X_train)\n",
    "\n",
    "eigenfaces = pca.components_.reshape((n_components, sizeRef, sizeRef))\n",
    "\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "otimização da SVM usando kernel radial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train_pca, X_test_pca = features(comp)\n",
    "param_grid = {'C': [1e0, 1e1, 1e2, 1e3, 5e3, 1e4, 5e4, 1e5, 5e6, 1e6],\n",
    "              'gamma': [0.00001, 0.0005, 0.0001, 0.0003, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
    "clf = GridSearchCV(\n",
    "    SVC(kernel='rbf', class_weight='balanced'), param_grid\n",
    ")\n",
    "clf = clf.fit(X_train_pca, y_train)\n",
    "#    print(\"Best estimator found by grid search:\")\n",
    "#    print(clf.best_estimator_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificação, Cálculo das métricas de classificação, e Relatório. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          batom       0.75      0.96      0.84        28\n",
      "   caixa de cha       0.81      0.68      0.74        19\n",
      "         caneca       0.71      0.63      0.67        27\n",
      "         caneta       0.83      0.97      0.89        30\n",
      "carreteis pesca       0.91      0.97      0.94        33\n",
      "          garfo       1.00      0.78      0.88        36\n",
      "          livro       0.94      0.59      0.73        27\n",
      "       parafuso       0.89      0.93      0.91        27\n",
      "     tampa 74mm       0.86      1.00      0.92        55\n",
      "          tenis       0.91      0.88      0.89        24\n",
      "\n",
      "       accuracy                           0.86       306\n",
      "      macro avg       0.86      0.84      0.84       306\n",
      "   weighted avg       0.87      0.86      0.85       306\n",
      "\n",
      "[[27  1  0  0  0  0  0  0  0  0]\n",
      " [ 1 13  2  1  1  0  0  1  0  0]\n",
      " [ 1  1 17  1  0  0  0  1  4  2]\n",
      " [ 0  0  0 29  0  0  0  1  0  0]\n",
      " [ 0  0  0  0 32  0  1  0  0  0]\n",
      " [ 6  0  0  0  0 28  0  0  2  0]\n",
      " [ 0  1  4  3  2  0 16  0  1  0]\n",
      " [ 0  0  0  0  0  0  0 25  2  0]\n",
      " [ 0  0  0  0  0  0  0  0 55  0]\n",
      " [ 1  0  1  1  0  0  0  0  0 21]]\n",
      "['batom', 'caixa de cha', 'caneca', 'caneta', 'carreteis pesca', 'garfo', 'livro', 'parafuso', 'tampa 74mm', 'tenis'] 600\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test_pca)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=classes))\n",
    "print(confusion_matrix(y_test, y_pred, labels=range(len(classes))))\n",
    "print(classes, comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
